{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a script here which takes as input the fir n cycles from a battery\n",
    "# And then predicts the degredation curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "import pickle as pkl\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from os import environ\n",
    "from os.path import join as oj\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import training.my_eval as my_eval\n",
    "import training.data_loader as dl\n",
    "from training.loss_functions import nll_loss\n",
    "from training.models import *\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the initial data, then feed it into the model so that it can \n",
    "# Predict the degredation curves for the cells \n",
    "results_path = '/Users/paolovincenzofreieslebendeblasio/Cell_Lifetime_prediction/LaurasModels/3782957491.pkl'\n",
    "results = pd.Series(pkl.load(open(results_path, \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load models here \n",
    "import training.models as models\n",
    "model_path  = '/Users/paolovincenzofreieslebendeblasio/Cell_Lifetime_prediction/LaurasModels'\n",
    "\n",
    "input_dim = 1   # Number of input features (e.g. discharge capacity)\n",
    "num_augment = 7  # three  values of charging schedule (avg and last) plus the variance\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "my_models = models.Uncertain_LSTM(1, \n",
    "                            7, \n",
    "                            num_hidden =  results.hidden_size, \n",
    "                            num_hidden_lstm =  results.hidden_size_lstm, \n",
    "                            seq_len= 100, \n",
    "                            n_layers =2, \n",
    "                            dropout =.0).to(device) \n",
    "\n",
    "my_models.load_state_dict(torch.load(oj(model_path,'3782957491'+\".pt\"),\n",
    "map_location=torch.device('cpu')))\n",
    "model = my_models.to(device)\n",
    "\n",
    "capacity_output_scaler = MinMaxScaler((-1, 1), clip=False).fit(\n",
    "    np.maximum(np.minimum([y[0:1]], 180), 180*0.8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"/Users/paolovincenzofreieslebendeblasio/battery-life-prediction/\"\n",
    "results_filename = \"14cells300CyclesData-HelgeSteinGroup.hdf5\"\n",
    "data_path = results_path + results_filename\n",
    "\n",
    "#Absolute path to where the data is stored \n",
    "data_dict = dl.load_data_all_channels(data_path)\n",
    "x, y, c, var = dl.get_capacity_input(\n",
    "    data_dict,\n",
    "    start_cycle=10,\n",
    "    stop_cycle=100, \n",
    ")\n",
    "\n",
    "qc_variance_scaler = StandardScaler().fit(var)\n",
    "var = qc_variance_scaler.transform(var)\n",
    "augmented_data = np.hstack([c, var])\n",
    "#x = dl.scale_x(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85835071 0.79935766 0.75716198 0.82812584 0.84017861 0.82845288\n",
      "  0.81685328 0.80478122 0.79252653 0.78717744 0.77789454 0.77242156\n",
      "  0.7585281  0.74511755 0.73680579 0.7288441  0.72434466 0.71824957\n",
      "  0.72031288 0.69219746 0.6813982  0.67239602 0.66699745 0.65704984\n",
      "  0.65132    0.63947746 0.63035669 0.62212549 0.61409945 0.60659723\n",
      "  0.59681979 0.58963532 0.58117303 0.57057763 0.56469339 0.56076716\n",
      "  0.55406906 0.53204077 0.53667535 0.52729818 0.51383755 0.50879932\n",
      "  0.50077176 0.49278396 0.48451199 0.47392043 0.46349257 0.4548259\n",
      "  0.44854705 0.43849283 0.43000997 0.4178245  0.40409397 0.39536797\n",
      "  0.39161208 0.38745647 0.38561785 0.37407606 0.35792365 0.3463504\n",
      "  0.33938449 0.33505113 0.32756052 0.32562552 0.30677927 0.29568081\n",
      "  0.28912389 0.28304343 0.26911781 0.26295688 0.25535744 0.24453167\n",
      "  0.23488085 0.23223112 0.21896516 0.21020675 0.20033349 0.19204543\n",
      "  0.18447394 0.1705797  0.16209354 0.15626276 0.1549088  0.14475282\n",
      "  0.14013738 0.1261865  0.11485898 0.10744535 0.10125446 0.09573253\n",
      "  0.08966913 0.08219372 0.07178875 0.06487625 0.05641693 0.04955496\n",
      "  0.04352511 0.03923515 0.03888697 0.01772004 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.84031175 0.82340965 0.80466405 0.78886759 0.77894575 0.76695839\n",
      "  0.75519562 0.74413159 0.72699093 0.71592953 0.70795751 0.69692679\n",
      "  0.68853272 0.67735401 0.66561407 0.65413993 0.65251091 0.65043263\n",
      "  0.64653947 0.63460607 0.6253397  0.61326431 0.60846506 0.60079225\n",
      "  0.59326931 0.58439604 0.57517008 0.56419631 0.55293478 0.5516281\n",
      "  0.54871887 0.54321856 0.52751206 0.51883085 0.50742638 0.50280706\n",
      "  0.49748008 0.49288871 0.48216993 0.47054891 0.46080367 0.44876473\n",
      "  0.44872703 0.44495297 0.44185624 0.42585761 0.41670401 0.40737231\n",
      "  0.39933254 0.39303856 0.38475096 0.37559674 0.36900141 0.36182326\n",
      "  0.34893793 0.34432183 0.33264255 0.32596836 0.3164951  0.30296887\n",
      "  0.29326605 0.28849723 0.28884757 0.28267902 0.27660193 0.25892876\n",
      "  0.24960143 0.2382983  0.2318556  0.22719538 0.2181503  0.20836277\n",
      "  0.19712971 0.18694729 0.17285276 0.17193779 0.16740833 0.15983154\n",
      "  0.1486875  0.13525221 0.12373767 0.11142418 0.10442357 0.10099094\n",
      "  0.0968219  0.08597877 0.07806636 0.07053634 0.06363131 0.0640532\n",
      "  0.05922872 0.05546243 0.04906026 0.04121943 0.0355923  0.03019162\n",
      "  0.02659389 0.02186462 0.01646956 0.01116032 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.79595518 0.79754888 0.79616688 0.79537887 0.79448678 0.79272172\n",
      "  0.79203987 0.78200821 0.77424356 0.76760034 0.77004647 0.76924592\n",
      "  0.76560703 0.73935031 0.68175915 0.68567145 0.62194462 0.56941217\n",
      "  0.5609758  0.64408143 0.61523247 0.625039   0.64375652 0.58515752\n",
      "  0.42403336 0.62719472 0.56790149 0.57607569 0.5765265  0.5787465\n",
      "  0.53414349 0.52827644 0.44635427 0.61199489 0.6399432  0.63084745\n",
      "  0.69113155 0.71575594 0.64252822 0.59941416 0.58103343 0.61106925\n",
      "  0.69115138 0.67901863 0.62118593 0.55701014 0.55298603 0.51057193\n",
      "  0.5143848  0.56509426 0.53493478 0.58010466 0.60875069 0.65348856\n",
      "  0.65075377 0.61649142 0.62533477 0.61142104 0.61595888 0.62887\n",
      "  0.59758739 0.56999131 0.63615431 0.58246778 0.56580999 0.58015879\n",
      "  0.59504929 0.62463469 0.62146776 0.61868186 0.6155328  0.60898309\n",
      "  0.60675962 0.60482687 0.60122208 0.59239824 0.57925388 0.58336566\n",
      "  0.57720458 0.57546547 0.5716048  0.54690189 0.55824518 0.56015578\n",
      "  0.55381088 0.55742619 0.5579629  0.55714335 0.54143179 0.5316761\n",
      "  0.50115074 0.49670238 0.45970515 0.44625295 0.44897906 0.45332683\n",
      "  0.37760837 0.23628812 0.37971823 0.35204191 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.71140691 0.7184345  0.74896743 0.69260575 0.71948216 0.7801104\n",
      "  0.74673208 0.69171549 0.68149553 0.67913943 0.63954605 0.75805586\n",
      "  0.7759046  0.77083173 0.75360998 0.75127752 0.75917918 0.75454164\n",
      "  0.7510928  0.73630536 0.71876957 0.70733255 0.7072103  0.70269827\n",
      "  0.68941097 0.68911723 0.68442652 0.68035138 0.67720361 0.67370085\n",
      "  0.6728182  0.66836535 0.6603992  0.65598039 0.65709917 0.65512087\n",
      "  0.66638252 0.64274694 0.63694593 0.62860157 0.6280456  0.62184489\n",
      "  0.61649422 0.60547824 0.59457465 0.58545104 0.58184758 0.57654921\n",
      "  0.57253843 0.56759367 0.55223185 0.54567608 0.53793868 0.53957858\n",
      "  0.53348461 0.52525533 0.51301687 0.50421103 0.49503533 0.49271056\n",
      "  0.49405583 0.48547326 0.47302498 0.46517956 0.45552725 0.45219681\n",
      "  0.4511918  0.44217456 0.43494176 0.42617003 0.41834901 0.40904631\n",
      "  0.40635789 0.39928513 0.39379799 0.388367   0.38141616 0.37201842\n",
      "  0.37048849 0.36705736 0.36620505 0.35435853 0.34610813 0.33730866\n",
      "  0.33094938 0.33263    0.32688487 0.31763428 0.30839985 0.29708208\n",
      "  0.29055621 0.28701121 0.28135044 0.27274901 0.26432358 0.25215624\n",
      "  0.2465853  0.23779245 0.18678737 0.23118595 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "max_val = 180  # nominal capacity for the cells which you are testing\n",
    "end_of_life_val = (0.8 * 180)  # batteries are considered dead after 80%. This should be .8*1.1\n",
    "\n",
    "x = np.minimum(x, max_val)\n",
    "x = np.maximum(x, end_of_life_val)\n",
    "\n",
    "x = (x - end_of_life_val) / (max_val - end_of_life_val)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85835071 0.79935766 0.75716198 0.82812584 0.84017861 0.82845288\n",
      "  0.81685328 0.80478122 0.79252653 0.78717744 0.77789454 0.77242156\n",
      "  0.7585281  0.74511755 0.73680579 0.7288441  0.72434466 0.71824957\n",
      "  0.72031288 0.69219746 0.6813982  0.67239602 0.66699745 0.65704984\n",
      "  0.65132    0.63947746 0.63035669 0.62212549 0.61409945 0.60659723\n",
      "  0.59681979 0.58963532 0.58117303 0.57057763 0.56469339 0.56076716\n",
      "  0.55406906 0.53204077 0.53667535 0.52729818 0.51383755 0.50879932\n",
      "  0.50077176 0.49278396 0.48451199 0.47392043 0.46349257 0.4548259\n",
      "  0.44854705 0.43849283 0.43000997 0.4178245  0.40409397 0.39536797\n",
      "  0.39161208 0.38745647 0.38561785 0.37407606 0.35792365 0.3463504\n",
      "  0.33938449 0.33505113 0.32756052 0.32562552 0.30677927 0.29568081\n",
      "  0.28912389 0.28304343 0.26911781 0.26295688 0.25535744 0.24453167\n",
      "  0.23488085 0.23223112 0.21896516 0.21020675 0.20033349 0.19204543\n",
      "  0.18447394 0.1705797  0.16209354 0.15626276 0.1549088  0.14475282\n",
      "  0.14013738 0.1261865  0.11485898 0.10744535 0.10125446 0.09573253\n",
      "  0.08966913 0.08219372 0.07178875 0.06487625 0.05641693 0.04955496\n",
      "  0.04352511 0.03923515 0.03888697 0.01772004 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.84031175 0.82340965 0.80466405 0.78886759 0.77894575 0.76695839\n",
      "  0.75519562 0.74413159 0.72699093 0.71592953 0.70795751 0.69692679\n",
      "  0.68853272 0.67735401 0.66561407 0.65413993 0.65251091 0.65043263\n",
      "  0.64653947 0.63460607 0.6253397  0.61326431 0.60846506 0.60079225\n",
      "  0.59326931 0.58439604 0.57517008 0.56419631 0.55293478 0.5516281\n",
      "  0.54871887 0.54321856 0.52751206 0.51883085 0.50742638 0.50280706\n",
      "  0.49748008 0.49288871 0.48216993 0.47054891 0.46080367 0.44876473\n",
      "  0.44872703 0.44495297 0.44185624 0.42585761 0.41670401 0.40737231\n",
      "  0.39933254 0.39303856 0.38475096 0.37559674 0.36900141 0.36182326\n",
      "  0.34893793 0.34432183 0.33264255 0.32596836 0.3164951  0.30296887\n",
      "  0.29326605 0.28849723 0.28884757 0.28267902 0.27660193 0.25892876\n",
      "  0.24960143 0.2382983  0.2318556  0.22719538 0.2181503  0.20836277\n",
      "  0.19712971 0.18694729 0.17285276 0.17193779 0.16740833 0.15983154\n",
      "  0.1486875  0.13525221 0.12373767 0.11142418 0.10442357 0.10099094\n",
      "  0.0968219  0.08597877 0.07806636 0.07053634 0.06363131 0.0640532\n",
      "  0.05922872 0.05546243 0.04906026 0.04121943 0.0355923  0.03019162\n",
      "  0.02659389 0.02186462 0.01646956 0.01116032 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.79595518 0.79754888 0.79616688 0.79537887 0.79448678 0.79272172\n",
      "  0.79203987 0.78200821 0.77424356 0.76760034 0.77004647 0.76924592\n",
      "  0.76560703 0.73935031 0.68175915 0.68567145 0.62194462 0.56941217\n",
      "  0.5609758  0.64408143 0.61523247 0.625039   0.64375652 0.58515752\n",
      "  0.42403336 0.62719472 0.56790149 0.57607569 0.5765265  0.5787465\n",
      "  0.53414349 0.52827644 0.44635427 0.61199489 0.6399432  0.63084745\n",
      "  0.69113155 0.71575594 0.64252822 0.59941416 0.58103343 0.61106925\n",
      "  0.69115138 0.67901863 0.62118593 0.55701014 0.55298603 0.51057193\n",
      "  0.5143848  0.56509426 0.53493478 0.58010466 0.60875069 0.65348856\n",
      "  0.65075377 0.61649142 0.62533477 0.61142104 0.61595888 0.62887\n",
      "  0.59758739 0.56999131 0.63615431 0.58246778 0.56580999 0.58015879\n",
      "  0.59504929 0.62463469 0.62146776 0.61868186 0.6155328  0.60898309\n",
      "  0.60675962 0.60482687 0.60122208 0.59239824 0.57925388 0.58336566\n",
      "  0.57720458 0.57546547 0.5716048  0.54690189 0.55824518 0.56015578\n",
      "  0.55381088 0.55742619 0.5579629  0.55714335 0.54143179 0.5316761\n",
      "  0.50115074 0.49670238 0.45970515 0.44625295 0.44897906 0.45332683\n",
      "  0.37760837 0.23628812 0.37971823 0.35204191 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.71140691 0.7184345  0.74896743 0.69260575 0.71948216 0.7801104\n",
      "  0.74673208 0.69171549 0.68149553 0.67913943 0.63954605 0.75805586\n",
      "  0.7759046  0.77083173 0.75360998 0.75127752 0.75917918 0.75454164\n",
      "  0.7510928  0.73630536 0.71876957 0.70733255 0.7072103  0.70269827\n",
      "  0.68941097 0.68911723 0.68442652 0.68035138 0.67720361 0.67370085\n",
      "  0.6728182  0.66836535 0.6603992  0.65598039 0.65709917 0.65512087\n",
      "  0.66638252 0.64274694 0.63694593 0.62860157 0.6280456  0.62184489\n",
      "  0.61649422 0.60547824 0.59457465 0.58545104 0.58184758 0.57654921\n",
      "  0.57253843 0.56759367 0.55223185 0.54567608 0.53793868 0.53957858\n",
      "  0.53348461 0.52525533 0.51301687 0.50421103 0.49503533 0.49271056\n",
      "  0.49405583 0.48547326 0.47302498 0.46517956 0.45552725 0.45219681\n",
      "  0.4511918  0.44217456 0.43494176 0.42617003 0.41834901 0.40904631\n",
      "  0.40635789 0.39928513 0.39379799 0.388367   0.38141616 0.37201842\n",
      "  0.37048849 0.36705736 0.36620505 0.35435853 0.34610813 0.33730866\n",
      "  0.33094938 0.33263    0.32688487 0.31763428 0.30839985 0.29708208\n",
      "  0.29055621 0.28701121 0.28135044 0.27274901 0.26432358 0.25215624\n",
      "  0.2465853  0.23779245 0.18678737 0.23118595 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    " #Scaling the QC, and cycle life \n",
    "\n",
    "#x_preprocessed = dl.remove_outliers(x_scaled,y) #\n",
    "x_smoothed = x\n",
    "\n",
    "# for seq_length in [40,]:\n",
    "max_steps = 1000\n",
    "num_models = 1\n",
    "num_samples = 20\n",
    "#used_idxs = test_idxs\n",
    "used_idxs = [0]\n",
    "mean_val = []\n",
    "cycle_dict = {}\n",
    "for seq_length in [100,]:  \n",
    "    test_seq_list = []\n",
    "    test_life_pred_list = []\n",
    "    test_seq_std_list = []\n",
    "    all_outputs_arr = np.empty( (len(used_idxs),max_steps,num_models, num_samples,))\n",
    "    # used_idxs =  np.arange(len(x))#for actually new data, use test_idxs=\n",
    "    supp_val_data = np.hstack([c[used_idxs, :3], var[used_idxs],np.ones((len(used_idxs),1))*np.log(seq_length) ])\n",
    "\n",
    "    #Take the scaled values for y, and the capacitance as a function of time \n",
    "    test_seq = x_preprocessed[used_idxs][:, :seq_length,None  ].copy()\n",
    "    extended_seq = np.swapaxes(np.reshape(np.repeat(np.swapaxes(test_seq, 0,-1)[:,:,:,None],\n",
    "                                                    num_samples, axis =-1), (1, seq_length, -1)),0,-1)\n",
    "\n",
    "    extended_supp_data = np.swapaxes(np.reshape(np.repeat(np.swapaxes(supp_val_data, 0,-1)[:,:,None],\n",
    "                                                          num_samples, axis =-1), (supp_val_data.shape[1], -1)),0,-1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        while((np.all(extended_seq[:,-1] < 1e-3) == False ) *(extended_seq.shape[1] < max_steps)):\n",
    "\n",
    "            supp_val_data_torch = torch.from_numpy(extended_supp_data).to(device).float()\n",
    "\n",
    "            test_seq_torch = torch.from_numpy(extended_seq[:, - seq_length:]).to(device).float()\n",
    "\n",
    "            model.reset_hidden_state()        \n",
    "            (state_mean_mean, state_var) = model(test_seq_torch, supp_val_data_torch)\n",
    "            \n",
    "            #Create a vector which creates the gaussian distribution\n",
    "            #The number of samples, corresponds to how well we sample the gaussian space\n",
    "            \n",
    "            if num_samples >1:\n",
    "                state_mean_noisy   = state_mean_mean  +  torch.normal(0, (torch.sqrt(state_var)))   \n",
    "            else:\n",
    "                state_mean_noisy   = state_mean_mean \n",
    "\n",
    "            state_mean_transformed = torch.from_numpy(capacity_output_scaler.inverse_transform(\n",
    "                state_mean_noisy.cpu().numpy())).to(device)\n",
    "            print(state_mean_transformed)\n",
    "            #Inversely transforms the predicted capacity into the correct value\n",
    "\n",
    "            mean_val.append(np.mean(state_mean_transformed.cpu().numpy()[0]))\n",
    "            state_mean_transformed[:,0] = state_mean_transformed[:,0]*(test_seq_torch[:, -1, 0 ])\n",
    "\n",
    "            extended_supp_data[:,-1] = np.log(np.exp(extended_supp_data[:,-1])+1)\n",
    "            extended_seq = np.hstack([extended_seq, state_mean_transformed.cpu().numpy()[:, None]])\n",
    "            #We append more and more of the extended seq state\n",
    "    used_steps = extended_seq.shape[1]\n",
    "    reshaped = np.swapaxes(np.reshape(np.swapaxes(extended_seq,0,1),(1,used_steps, -1, num_samples)),0,-2)\n",
    "    all_outputs_arr[:,:used_steps,0,:] = reshaped[:,:,0]\n",
    "\n",
    "all_outputs_arr = np.reshape(np.transpose(all_outputs_arr, (0,2,3, 1)), (len(used_idxs), -1, max_steps))\n",
    "cycle_dict[seq_length] = np.copy(all_outputs_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8746da0e80>]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(cycle_dict[50][0][0][0:52])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
